{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../fastai/') #fastai version 1.0\n",
    "from fastai.vision import *\n",
    "from fastai.vision.learner import model_meta\n",
    "\n",
    "sys.path.append('../models-pytorch/pretrained-models.pytorch')\n",
    "import pretrainedmodels\n",
    "from pretrainedmodels import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models import *\n",
    "from torchsummary import summary\n",
    "from pathlib import Path\n",
    "from functools import partial, update_wrapper\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import PIL\n",
    "import imageio\n",
    "\n",
    "PATH = Path('/home/Deep_Learner/work/network/datasets/2018_dsb')\n",
    "TRAIN_NAME = 'stage1_train_fixed'\n",
    "TRAIN = PATH/TRAIN_NAME\n",
    "MASKS_NAME = 'stage1_masks'\n",
    "MASKS = PATH/MASKS_NAME\n",
    "CSV_NAME = 'stage1_train_labels.csv'\n",
    "TRAIN_PATHS_CSV_NAME = 'stage1_train_paths_fixed.csv'\n",
    "TRAIN_PATHS_CSV = PATH/TRAIN_PATHS_CSV_NAME\n",
    "LABELS = PATH/CSV_NAME\n",
    "TEST_NAME = 'stage1_test'\n",
    "TEST = PATH/TEST_NAME\n",
    "SAMPLE = PATH/'stage1_sample_submission.csv'\n",
    "SUBMISSIONS = PATH/'submissions'\n",
    "SUBMISSIONS.mkdir(exist_ok=True)\n",
    "\n",
    "nw = 8   #number of workers for data loader\n",
    "torch.backends.cudnn.benchmark=True\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "def batch_stats(self, funcs:Collection[Callable]=None)->Tensor:\n",
    "        \"Grab a batch of data and call reduction function `func` per channel\"\n",
    "        funcs = ifnone(funcs, [torch.mean,torch.std])\n",
    "        x = self.one_batch(ds_type=DatasetType.Train, denorm=False)[0].cpu()\n",
    "        return [func(channel_view(x), 1) for func in funcs]\n",
    "\n",
    "    \n",
    "vision.data.ImageDataBunch.batch_stats = batch_stats\n",
    "\n",
    "def split_path(path:Union[str, Path])-> list:\n",
    "    return os.path.normpath(path).split(os.sep)\n",
    "    \n",
    "\n",
    "sz = 512\n",
    "bs = 8\n",
    "epochs_freezed = 1\n",
    "epochs_unfreezed = 20\n",
    "\n",
    "#fastai defaults\n",
    "tta_beta = 0.4 \n",
    "tta_scale = 1.35\n",
    "dropout = 0.5\n",
    "wd = 0.01\n",
    "\n",
    "#non defaults\n",
    "#wd = 0.1 not better for se_resnext50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## train paths csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(LABELS)\n",
    "df.head()\n",
    "\n",
    "ids = list(set(df.ImageId))\n",
    "\n",
    "paths = []\n",
    "\n",
    "for n, i in tqdm(enumerate(ids), total=len(ids)):\n",
    "    p = Path(f'{TRAIN_NAME}/{i}/images/{i}.png')\n",
    "    try:\n",
    "        open_image(PATH/p)\n",
    "        paths.append(p)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "len(paths)\n",
    "\n",
    "df_paths = pd.DataFrame(data=paths, columns=['paths'])\n",
    "\n",
    "df_paths.to_csv(index=False, path_or_buf=TRAIN_PATHS_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine single nucleus masks to one mask per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10577f31f8748d48b3574462f9d7657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=664), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_mask(path:Union[str,Path], size:int)->np.array:\n",
    "    \"\"\"\n",
    "    path: path to folder with masks of single nuclei\n",
    "    size: size for resizing imgs\n",
    "    \"\"\"\n",
    "    shape = open_mask(list(path.iterdir())[0]).shape   \n",
    "    mask = np.zeros(shape=(shape[1], shape[2], 1),dtype=np.uint8)\n",
    "    for m in list(path.iterdir()):\n",
    "        nucleus = np.array(PIL.Image.open(m), dtype=np.uint8)\n",
    "        nucleus = np.expand_dims(nucleus, axis=-1)\n",
    "        mask = np.maximum(mask, nucleus)\n",
    "    return np.squeeze(mask)\n",
    "\n",
    "    \n",
    "def show_mask(mask:np.array):\n",
    "    plt.imshow(np.squeeze(mask))\n",
    "\n",
    "    \n",
    "def save_mask(mask:np.array, path:Path, filename:str, suffix:str):\n",
    "    path.mkdir(exist_ok=True)\n",
    "    imageio.imwrite(f'{path}/{filename}{suffix}', mask)\n",
    "\n",
    "ids = [os.path.splitext(os.path.split(p)[-1])[0] for p in pd.read_csv(TRAIN_PATHS_CSV).paths]\n",
    "\n",
    "for i in tqdm(ids[:]):\n",
    "    p = PATH/TRAIN_NAME/i/'masks'\n",
    "    mask = get_mask(p, sz)\n",
    "    save_mask(mask, MASKS, i, '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegmentationItemList (664 items)\n",
       "Image (3, 1024, 1024),Image (3, 256, 320),Image (3, 1024, 1024),Image (3, 520, 696),Image (3, 520, 696)\n",
       "Path: /home/Deep_Learner/work/network/datasets/2018_dsb"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = SegmentationItemList.from_csv(path=PATH, csv_name=TRAIN_PATHS_CSV_NAME); s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s.split_by_rand_pct(valid_pct=0.2, seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_fn(x): return PATH/MASKS/os.path.split(x)[-1]\n",
    "s = s.label_from_func(get_y_fn, classes=array(['background', 'nucleus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
